### Understanding Artificial Intelligence, Language Models, and Effective Prompting

So far, we have learned:

- How **computers** make life faster.
- How the **Internet** connects the world and opens up possibilities for the future.
- How **web apps** are in high demand and help us do so much online.

But all of these are still **systems without intelligence** â€” they follow instructions exactly as we code them.

Now, itâ€™s time to **add intelligence** â€” a technology that not only **saves human time** but can also **help humans make decisions**. This is possible with **Artificial Intelligence (AI).**

---

### ğŸ‘€ A Simple Observation

You may have used **face unlock** on your phone.

<image src="https://coding-platform.s3.amazonaws.com/dev/lms/tickets/c7bf5c19-a7a2-48cd-8727-2962bea3b831/HZswk1YVUZlgqwp0.png" width="300px" />

- What if another person shows their face to unlock? That person also has eyes, nose, mouth, right?
- Will the phone unlock just because the face has similar features?

No! This is **not just code running**.
There is **intelligence behind the scenes** â€” the system **decides** whether the face is yours or someone elseâ€™s. âœ…

This is what **Artificial Intelligence** is â€” going **beyond traditional code or algorithms** to make smart decisions.

---

### ğŸ”¹ What Weâ€™ll Learn Next

- What **AI** is and how it works.
- Advancements like **Generative AI (Gen AI)** and **Agentic AI**.
- Key **terminologies** you need to know before diving deeper.

---

### ğŸ§­ **Where Are We Heading?**

Letâ€™s now dive into:

- **What is AI?**
- **How has AI evolved over time?**
- Understanding key concepts like:

  - AI (Artificial Intelligence)
  - ML (Machine Learning)
  - DL (Deep Learning)
  - LLMs (Large Language Models)
  - And many more!

- And weâ€™ll wrap up with **hands-on prompting techniques**â€”how to talk to AI effectively!

#### What is AI?

- Artificial intelligence (AI) is technology that enables computers and machines to simulate human learning, comprehension, problem solving, decision making, creativity and autonomy.

- Applications and devices equipped with AI can see and identify objects. They can understand and respond to human language.
- They can learn from new information and experience. They can make detailed recommendations to users and experts.
- They can act independently, replacing the need for human intelligence or intervention (a classic example being a self-driving car).

- But in 2024, most AI researchers, practitioners and most AI-related headlines are focused on breakthroughs in generative AI (gen AI), a technology that can create original text, images, video and other content.

- To fully understand generative AI, itâ€™s important to first understand the technologies on which generative AI tools are built: machine learning (ML) and deep learning.

![AI-ML-DL-Gen AI - 1](https://coding-platform.s3.amazonaws.com/dev/lms/tickets/138ed213-e3bc-410b-859b-b58614b87dca/tdmIMpJtwUP3mATW.png)

![AI-ML-DL-Gen AI - 2](https://coding-platform.s3.amazonaws.com/dev/lms/tickets/734b8a99-a652-4bc3-9dff-2969df3f81e9/vDDjlRetRtDelclt.png)

#### Machine learning

- Directly underneath AI, we have machine learning, which involves creating models by training an algorithm to make predictions or decisions based on data. It encompasses a broad range of techniques that enable computers to learn from and make inferences based on data without being explicitly programmed for specific tasks.
- There are many types of machine learning techniques or algorithms, including `linear regression`, `logistic regression`, `decision trees`, `support vector machines (SVMs)` and more. Each of these approaches is suited to different kinds of problems and data.
- But one of the most popular types of machine learning algorithm is called a `neural network` (or `artificial neural network`). `Neural networks` are modeled after the `human brain's` structure and function. A neural network consists of interconnected layers of nodes (analogous to neurons) that work together to process and analyze complex data.

- Detection of Breast Cancer is an best example, [Breast Cancer Detection](https://www.breastcancer.org/screening-testing/artificial-intelligence)

#### Deep learning

![Deep Learning](https://coding-platform.s3.amazonaws.com/dev/lms/tickets/aa0732f0-0e97-4ad7-ad76-1c51bf51e902/krkZfpgvppaWMmFs.png)

- Deep learning is a subset of machine learning that uses multilayered neural networks, called deep neural networks, that more closely simulate the complex decision-making power of the human brain.

- Deep neural networks include an input layer, at least three but usually hundreds of hidden layers, and an output layer, unlike neural networks used in classic machine learning models, which usually have only one or two hidden layers.

- These multiple layers enable unsupervised learning: they can automate the extraction of features from large, unlabeled and unstructured data sets, and make their own predictions about what the data represents.

- Because deep learning doesnâ€™t require human intervention, it enables machine learning at a tremendous scale.It's used in fields like natural language processing, image recognition, and even in autonomous vehicles.

- Deep learning also enables:

  - `Semi-supervised learning`, which combines supervised and unsupervised learning by using both labeled and unlabeled data to train AI models for classification and regression tasks.

  - `Self-supervised learning`, which generates implicit labels from unstructured data, rather than relying on labeled data sets for supervisory signals.

  - `Reinforcement learning`, which learns by trial-and-error and reward functions rather than by extracting information from hidden patterns.

  - `Transfer learning`, in which knowledge gained through one task or data set is used to improve model performance on another related task or different data set.

#### Generative AI

- Generative AI, sometimes called "gen AI", refers to deep learning models that can create complex original content such as long-form text, high-quality images, realistic video or audio and more in response to a userâ€™s prompt or request.
- At a high level, generative models encode a simplified representation of their training data, and then draw from that representation to create new work thatâ€™s similar, but not identical, to the original data.
- Generative models have been used for years in statistics to analyze numerical data. But over the last decade, they evolved to analyze and generate more complex data types. This evolution coincided with the emergence of three sophisticated deep learning model types:

  - Variational autoencoders or VAEs, which were introduced in 2013, and enabled models that could generate multiple variations of content in response to a prompt or instruction.

  - Diffusion models, first seen in 2014, which add "noise" to images until they are unrecognizable, and then remove the noise to generate original images in response to prompts.

  - Transformers (also called transformer models), which are trained on sequenced data to generate extended sequences of content (such as words in sentences, shapes in an image, frames of a video or commands in software code). Transformers are at the core of most of todayâ€™s headline-making generative AI tools, including ChatGPT and GPT-4, Copilot, BERT, Bard and Midjourney.

#### ğŸ¤– **Diffference between Artificial Intelligence (AI) & Generative AI (GenAI) and its application**

AI is a broad field where machines are designed to mimic human intelligence to solve problems, make decisions, or perform tasks.

#### ğŸ”¹ **Examples of AI:**

1. **Face Recognition in Phones** â€“ Unlocking your phone using your face.
2. **Spam Filters in Email** â€“ Detects and moves spam to the spam folder.
3. **Self-driving Cars** â€“ Detect objects, interpret signs, and make driving decisions.
4. **Voice Assistants (e.g., Alexa, Siri)** â€“ Understand and respond to voice commands.
5. **Recommendation Systems (Netflix, YouTube)** â€“ Suggests content based on your behavior.

---

### âœ¨ **Generative AI (GenAI)**

GenAI refers to AI that can **generate new content**, such as text, images, audio, or video, based on what it has learned.

#### ğŸ”¹ **Examples of Generative AI:**

1. **ChatGPT** â€“ Generates human-like text answers or creative writing.
2. **DALLÂ·E** â€“ Creates original images from text prompts.
3. **Sora (by OpenAI)** â€“ Generates videos based on descriptions.
4. **MusicLM (Google)** â€“ Generates original music from text inputs.
5. **Deepfake Generators** â€“ Create realistic fake videos using real faces/voices.

---

### Quick Summary:

| Feature               | AI Example                         | GenAI Example                      |
| --------------------- | ---------------------------------- | ---------------------------------- |
| Task Automation       | Spam detection in Gmail            | Email writing assistant (ChatGPT)  |
| Prediction & Decision | Credit card fraud detection        | Story or blog generation (ChatGPT) |
| Recognition           | Face or speech recognition systems | Voice cloning or face generation   |

---

##### Breif History Of Evolution of AI

- 1950 - Alan Turing publishes Computing Machinery and Intelligence. In this paper, Turing famous for breaking the German ENIGMA code during WWII and often referred to as the "father of computer science" asks the following question: "Can machines think?"
- 1956 - John McCarthy coins the term "artificial intelligence"
- 1980 - Neural networks, which use a backpropagation algorithm to train itself, became widely used in AI applications.
- 1997 - Deep Blue (developed by IBM) beat the world chess champion, Gary Kasparov, in a highly-publicized match, becoming the first program to beat a human chess champion.
- 1997 - Windows released a speech recognition software (developed by Dragon Systems).
- 2006 - Companies such as Twitter, Facebook, and Netflix started utilizing AI as a part of their advertising and user experience (UX) algorithms.
- 2011 - IBM WatsonÂ® beats champions Ken Jennings and Brad Rutter at Jeopardy! Also, around this time, `data science` begins to emerge as a `popular discipline`.
- 2011 - Apple released Siri, the first popular virtual assistant.
- 2015 - Baidu's Minwa supercomputer uses a special deep neural network called a convolutional neural network to identify and categorize images with a higher rate of accuracy than the average human.
- 2020 - OpenAI started beta testing GPT-3, a model that uses Deep Learning to create code, poetry, and other such language and writing tasks. While not the first of its kind, it is the first that creates content almost indistinguishable from those created by humans.
- 2021 - OpenAI developed DALL-E, which can process and understand images enough to produce accurate captions, moving AI one step closer to understanding the visual world.
- 2022 - A rise in large language models or LLMs, such as OpenAIâ€™s ChatGPT, creates an enormous change in performance of AI and its potential to drive enterprise value. With these new generative AI practices, deep-learning models can be pretrained on large amounts of data.

### Part 2: AI for Developers:

#### AI Engineers vs AI Researchers

- _Researchers_ explore theoretical advancements, create new architectures.
- _Engineers_ implement, fine-tune, and deploy existing models.

- In this session we focus for AI Engineers, before proceeding towards Implementation, we should understand how exactly AI works what are its dependencies, key terminologies etc,

#### How generative AI works

- In general, generative AI operates in three phases:

  - **Training**, to create a foundation model.
  - **Tuning**, to adapt the model to a specific application.
  - **Generation**, evaluation and more tuning, to improve accuracy.

- **Training**

  - Generative AI begins with a "foundation model"; a deep learning model that serves as the basis for multiple different types of generative AI applications.
    ![AI Models](https://coding-platform.s3.amazonaws.com/dev/lms/tickets/12c38939-e9aa-467c-bf99-cb8e38068654/dbqS3OHexpjKbeCT.png)

  - **What is AI Model??**
  - An AI model is a program that has been trained on a set of data to recognize certain patterns or make certain decisions without further human intervention. Artificial intelligence models apply different algorithms to relevant data inputs to achieve the tasks, or output, theyâ€™ve been programmed for.
  - Algorithms vs. models
    - Though the two terms are often used interchangeably in this context, they do not mean quite the same thing.
    - Algorithms are procedures, often described in mathematical language or pseudocode, to be applied to a dataset to achieve a certain function or purpose.
    - Models are the output of an algorithm that has been applied to a dataset.
    - _`In simple terms, an AI model is used to make predictions or decisions and an algorithm is the logic by which that AI model operates.`_
  - The most common foundation models today are `Large Language Models (LLMs)`, created for text generation applications. But there are also foundation models for image, video, sound or music generation, and multimodal foundation models that support several kinds of content.
  - **What are LLMs?**

    - Large language models (LLMs) are a category of foundation models trained on immense amounts of data making them capable of understanding and generating natural language and other types of content to perform a wide range of tasks.

    - **How LLMs works?**

![How LLMs Works](https://coding-platform.s3.amazonaws.com/dev/lms/tickets/5db4251f-5896-48b7-bded-44385d69191f/PAEksixScuNQjfCn.png)

LLMs generate text by predicting what comes next in a sentence, one piece (token) at a time.

**Example:**
Sentence: `When I hear rain on my roof, I _______ in my kitchen.`

The model estimates probabilities for different options:

- cook soup â†’ 9.4%
- warm up a kettle â†’ 5.2%
- cower â†’ 3.6%
- nap â†’ 2.5%
- relax â†’ 2.2%

> It picks the next word based on these probabilities.

**Temperature Setting:**

- **Low temperature (0.1):** Safe and predictable â†’ usually picks the most likely option, e.g., "cook soup".
- **High temperature (0.8â€“1.0):** More creative â†’ might pick "warm up a kettle" or something unusual.

**How the model predicts text:**
It predicts **one token at a time**, then moves to the next:

```text
When I hear rain on my roof, I â†’ cook â†’ soup â†’ in â†’ my â†’ kitchen.
```

---

### **Simplified Working Steps of an LLM**

1. **Tokenization â€“ â€œBreaking text into chunksâ€**

   - The input is split into **tokens** (words, subwords, or characters).
   - Example: `"ChatGPT is amazing"` â†’ `["Chat", "G", "PT", " is", " amazing"]`

2. **Embedding â€“ â€œTurning tokens into numbersâ€**

   - Each token is converted to a **vector** (list of numbers) representing meaning.
   - Words with similar meanings, like "king" and "queen", get similar vectors.

3. **Transformers â€“ â€œUnderstanding contextâ€**

   - The **Transformer** architecture uses **self-attention** to figure out which words are important to each other.
   - Example: `"The dog chased its tail"` â†’ model understands "its" refers to "dog".
   - Transformers process all tokens at once and use multiple layers to improve understanding.
   - GPT (Generative Pre-trained Transformer) is built using this architecture.

4. **Output Prediction â€“ â€œGenerating next tokenâ€**

   - The model predicts the most likely next token and keeps doing this until the text is complete.
   - Example:
     Input: `"Once upon a time, there was a"`
     Output: `"king"` â†’ `"who"` â†’ `"lived"` â†’ `"in"` â†’ `"a"` â†’ `"castle"` ...

---

### **Tuning the Model**

After training, LLMs are **fine-tuned** for specific tasks:

1. **Fine-tuning:**

   - Feed the model task-specific examples and correct answers so it performs better for your application.

2. **Reinforcement Learning with Human Feedback (RLHF):**

   - Humans review outputs and give feedback to improve the model.
   - Example: People correct a chatbotâ€™s responses so it learns to answer better.

3. **Generation, evaluation and more tuning**

   - Developers and users often check how well their generative AI apps work and make improvements regularly, sometimes every week.
   - The main AI model itself (called the foundation model) is updated much less often â€” maybe once a year or every 18 months.
   - Another way to improve AI output is **Retrieval-Augmented Generation (RAG)**. This lets the AI look at extra information outside its training data to give more accurate answers.

---

### Important Terminologies Should know while using AI Models

### 1. **Parameters**

> Parameters are like the **memory of the AI** â€” the things it learns during training.

---

**Example:**
Imagine teaching a child to recognize animals. After many examples, they learn that animals with four legs, a tail, and that meow are usually cats.
AI works the same way â€” it **learns patterns from data**, and these patterns are stored as **parameters**.

---

**In AI terms:**

- Large AI models like GPT-3 or GPT-4 adjust **billions of parameters** during training.
- These parameters decide how likely a word should follow another word in a sentence.
- We can get AI Models trained with 0.6 B parameters to 480 parameters
- **More parameters = usually more accurate**, but also requires **more GPUs (powerful processors)** and **higher costs** to train and run.

---

**Key Points to Remember:**

- Not all AI models are trained for the same task.
- Even if two models both have billions of parameters, their **skills can differ**.
- **AI Engineers must carefully choose the right model** for the right job.
  **Example of why choosing the right model matters:**

  - **DeepSeek R** can also generate code, but the **code quality and accuracy** from **DeepSeek Coder** is much higher.
  - **DALLÂ·E** is trained for **image generation** â€” using it for coding tasks makes no sense.
  - So, using the wrong model for a task is like using a calculator to play music â€” itâ€™s simply not built for that purpose.
  - Now currently at the Day 4 of the Trial Week, No need to worry about which model to choose, use ChatGPT, Gemini that is sufficient

---

**Examples of AI Models:**

- **GPT Models (e.g., GPT-4)** â€“ by **OpenAI**
  General purpose â†’ answering questions, writing, reasoning, explaining concepts.
- **DeepSeek R** â€“ by **DeepSeek**
  Specialized for reasoning tasks.
- **DeepSeek Coder** â€“ by **DeepSeek**
  Specialized for code generation in many programming languages.
- **DALLÂ·E** â€“ by **OpenAI**
  Trained to generate images from text prompts.
- **Whisper** â€“ by **OpenAI**
  Trained for speech-to-text (audio â†’ written text).
- **Stable Diffusion** â€“ by **Stability AI**
  Trained for generating realistic and creative images.
- **MidJourney** â€“ by **MidJourney Inc.**
  Trained for artistic and creative image generation.
- **LLaMA (Large Language Model Meta AI)** â€“ by **Meta (Facebook)**
  Open-source family of models â†’ used in many research and commercial applications.
- **Mistral** â€“ by **Mistral AI**
  Open-source, efficient LLMs â†’ optimized for performance and cost.
- **Qwen (Tongyi Qianwen)** â€“ by **Alibaba**
  Large language model family â†’ general purpose and multilingual capabilities.

---

### 2. **Temperature**

> Temperature controls how **creative or predictable** the AIâ€™s output is.

- **Low temperature (0.2):** Safe, consistent answers.
- **High temperature (0.9):** More creative, sometimes unexpected answers.

---

**Example Prompt:** _â€œWhatâ€™s the color of the sky?â€_

- ğŸŒ¡ **Temperature = 0.2 (Low / Predictable)**

  - Output: **â€œThe sky is blue.â€**
    ğŸ‘‰ Safe, factual, and consistent.

- ğŸŒ¡ **Temperature = 0.9 (High / Creative)**

  - Output 1: **â€œThe sky is a canvas of shifting colors â€” sometimes orange at sunset, sometimes purple after a storm.â€**
  - Output 2: **â€œToday the sky looks like cotton candy, painted with pink and violet streaks.â€**
    ğŸ‘‰ More imaginative, surprising, and less consistent.

**ğŸ”‘ Analogy:**
Temperature = **spice level in food**.

- Low = plain and safe.
- High = bold and surprising.

---

### 3. **Hallucination**

> A hallucination is when the AI gives an answer that **sounds correct but is wrong**.

AI doesnâ€™t know facts; it guesses based on patterns it has seen. Sometimes it mixes them up and sounds confident.

**Example:**
Question: â€œWho invented the lightbulb?â€
AI says: â€œAlbert Einsteinâ€ â†’ Wrong! (It was Thomas Edison.)

**Analogy:**
Itâ€™s like a friend who confidently gives a wrong quiz answer â€” you might believe them until you check.

---

### **CPU vs. GPU â€“ Made Simple**

We can see the terminology like AI used GPU, then comes what is this GPU??, we know CPU, yes let us understand what is the difference between both
![GPU vs CPU](https://coding-platform.s3.amazonaws.com/dev/lms/tickets/e3ce022f-6377-41a7-8fe6-538f5c8f59ba/nmwkyIDHRwTWKBdW.png)

| ğŸ” Feature    | ğŸ§© **CPU**                                     | ğŸ® **GPU**                                                    |
| ------------- | ---------------------------------------------- | ------------------------------------------------------------- |
| **Full Form** | Central Processing Unit                        | Graphics Processing Unit                                      |
| **Main Job**  | Handles all general tasks (browsing, apps, OS) | Specializes in fast math for images and AI                    |
| **Cores**     | Few (4â€“16)                                     | Many (hundreds or thousands)                                  |
| **Strength**  | Great at doing one thing at a time, very well  | Great at doing many things at the same time                   |
| **Use In AI** | Okay for small models or simple tasks          | Perfect for training and running large AI models like ChatGPT |
| **Example**   | Typing in Word, Browsing                       | Gaming, Video Editing, AI Image Generation                    |

---

### âš™ï¸ **Analogy:**

- **CPU** = A smart person solving one tough problem at a time.
- **GPU** = A large group of helpers solving lots of small problems together.

---

### ğŸ‘¨â€ğŸ« Simple Summary:

> â€œCPU is your computerâ€™s brain. GPU is like a turbo engine â€” perfect for heavy tasks like AI and graphics.â€

### ğŸ¤– Agentic AI

- **What it is:** AI that not only generates but also **acts like an â€œagentâ€** â€” it can make decisions, take actions, use tools, and interact with systems **without constant human instructions**.
- **How it works:** Combines Gen AI + automation + reasoning â†’ can break a big task into steps, plan, and execute them.
- **Key point:** Itâ€™s **proactive** â€“ can perform tasks end-to-end.

**Example Use Cases:**

- An **AI travel agent**:

  - You say: â€œBook me a trip to Goa next weekend.â€
  - Agentic AI will â†’ search flights, compare prices, check hotels, and even book the trip for you (by interacting with APIs).

- An **AI coding agent (e.g., Devin AI, OpenAI o1)**:

  - You give a high-level request: â€œBuild me a weather app.â€
  - It â†’ plans the app, writes code, tests it, fixes bugs, and deploys.

## ![Agentic AI](https://coding-platform.s3.amazonaws.com/dev/lms/tickets/caf88bf0-c773-44c9-9a69-7df3c618f587/byDJgN1jvfOWPO10.png)

### ğŸ”¹ Key Difference

| Feature | **Generative AI**        | **Agentic AI**                               |
| ------- | ------------------------ | -------------------------------------------- |
| Nature  | Reactive (gives outputs) | Proactive (takes actions)                    |
| Scope   | Creates content          | Plans + Executes tasks                       |
| Example | Write an essay on AI     | Research + Write + Format + Submit the essay |
| Control | Needs human step-by-step | Can self-direct with goals                   |

---

- In Furture, that is in Upcoming Modules, you will be trained how to use AI Tools in your Coding Journy

---

### Part 3.0 Prompting

#### What is prompting?

An AI prompt is the input submitted to a large language model (LLM) via a generative artificial intelligence (GenAI) platform, like OpenAI's ChatGPT or Microsoft Copilot. The prompt can be defined as a question, command, statement, code sample or other form of text.

- **Why Proper AI Prompting is Essential:**

- Proper prompting is crucial because it helps guide the AI to generate accurate, relevant, and useful responses. A well-structured prompt gives the AI clear instructions, context, and expectationsâ€”reducing confusion and improving output quality. It allows users to control the tone, format, and depth of the answer, making interactions with AI more efficient and purposeful. Just like asking the right question leads to the right answer, effective prompting ensures the AI delivers meaningful results.

- **Example: Bad Prompt vs. Good Prompt**
- **Bad Prompt**

  > "Tell me about trees."

  - **Why it's bad:**

  - Too vague
  - No clarity on what type of trees, purpose, or format
  - AI might talk about random facts or give a generic answer

- **Good Prompt**
  > "Explain the importance of trees in controlling air pollution, in 3 simple bullet points, for school students."
  - **Why it's good:**
    - Clear topic: trees & air pollution
    - Defined format: bullet points
    - Specific audience: school students
    - Ensures relevance, simplicity, and structure

Here is a **well-structured explanation of different types of prompting in AI**, suitable for students. These techniques are especially relevant when working with **Large Language Models (LLMs)** like ChatGPT, GPT-4, etc.

---

## ğŸ“Œ Types of Prompting in AI

---

### 1. ğŸŸ¡ **Zero-Shot Prompting**

**Definition**:
The model is asked to perform a task **without giving any example**.

**Use Case**:
When the model is already trained and capable of understanding the task from the instruction alone.

**Example**:

> â€œTranslate this sentence into French: â€˜How are you?â€™â€
> The model will answer: â€œComment Ã§a va ?â€

---

### 2. ğŸŸ¢ **One-Shot Prompting**

**Definition**:
The model is given **one example** before asking it to perform the same kind of task.

**Use Case**:
To help the model understand the pattern expected in the output.

**Example**:

> Example: â€œTranslate to French: â€˜Good morningâ€™ â†’ â€˜Bonjourâ€™
> Now, translate: â€˜Thank youâ€™ â†’â€

---

### 3. ğŸ”µ **Few-Shot Prompting**

**Definition**:
The model is given **a few examples (2â€“5)** before asking it to continue the pattern.

**Use Case**:
Improves accuracy and consistency, especially for more complex or ambiguous tasks.

**Example**:

> Refer the previous emails:
>
> 1. _Subject: Meeting reschedule â€” The meeting on Monday has been moved to Wednesday at 3 PM. Please confirm your availability._
> 2. _Subject: Project update â€” The client approved the design. We will start development next week._
>    Now write a similar email to inform the team about the new office holiday schedule.

---

### 4. ğŸ§  **Chain-of-Thought Prompting**

**Definition**:
The model is guided to **explain its reasoning step by step** before giving the final answer.

**Use Case**:
Used in **logical reasoning**, **math**, and **multi-step questions**.

**Example**:

> â€œIf a pencil costs â‚¹5 and a pen costs â‚¹10, how much will 2 pencils and 1 pen cost?
> Think step-by-step.â€

Output:

- Pencil = â‚¹5 â†’ 2 pencils = â‚¹10
- Pen = â‚¹10
- Total = â‚¹10 + â‚¹10 = â‚¹20

---

### 5. ğŸ§‘â€ğŸ« **Role Prompting**

**Definition**:
You assign a **role or persona** to the AI to shape how it responds.

**Use Case**:
To control tone, style, or perspective of the response.

**Example**:

> â€œYou are a history teacher. Explain World War I in simple terms to a 6th-grade student.â€

---

### 6. ğŸ” **Self-Critique Prompting (Reflexion)**

**Definition**:
The model is prompted to **review or critique its own answer** and improve it.

**Use Case**:
Helps the model to revise for better accuracy or clarity.

**Example**:

> First: â€œExplain Newtonâ€™s First Law.â€
> Then: â€œNow check your explanation and improve it for clarity and correctness.â€

### Part 4, Final Touch, The Future with AI

### **Watch the Following Video and then we will have a furthur discussion**

ğŸ¥ [E-Eye: An AI-Based Elephant Movement Prediction Model](https://coding-platform.s3.amazonaws.com/dev/lms/tickets/4c52f3b8-4507-47f7-86c2-326d41cb325e/1UbaIsJ3NgtZNFL0.mp4)

<iframe 
    width="640" 
    height="360" 
    src="https://coding-platform.s3.amazonaws.com/dev/lms/tickets/4c52f3b8-4507-47f7-86c2-326d41cb325e/1UbaIsJ3NgtZNFL0.mp4" 
    title="E-Eye: AI-Based Elephant Movement Prediction" 
    frameborder="0" 
    allowfullscreen
></iframe>

---

#### âœï¸ **Think and Reflect**

- What are your thoughts on this solution?

* In the past, **software developers** could build systems through code that sent warnings or turned on hazard lights when an elephant arrived. But such systems **could not decide** whether an elephant was actually present â€” they only followed predefined instructions.

* With **AI**, itâ€™s different. Thereâ€™s **more than just code** â€” something intelligent is working behind the scenes.

* The system can now **detect elephants** based on features like **size, shape, walking patterns**, and even **thermal or movement patterns**.

* It can then **automatically send warnings** to train drivers when an elephant approaches the railway track â€” all **without human intervention**.

* This kind of **autonomous decision-making** is powered by **Artificial Intelligence (AI)**. It represents the future, where AI-driven systems will help not just in **technology**, but also in protecting the **environment, human lives, and wildlife**.

* And this is just one example â€” such advancements will continue to grow with the help of **Generative AI, Agentic AI, and many more AI innovations in the future.**

---
